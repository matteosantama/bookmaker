{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from typing import Tuple, List, Union\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(_type: str) -> Tuple[torch.tensor, torch.tensor]:\n",
    "    \"\"\"Retrieve X, Y data from the proper directory. You can\n",
    "    specify whether you want it to be pulled from /train, /dev, \n",
    "    or /test, and all the *-data.csv files will be loaded in.\n",
    "    \"\"\"\n",
    "    \n",
    "    if _type not in {'train', 'dev', 'test'}:\n",
    "        msg = f\"{_type} not supported. Try 'train', 'dev', or 'test'.\"\n",
    "        raise RuntimeError(msg)\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    data_path = os.path.join('data', _type, '*-data.csv')\n",
    "    for fp in glob.glob(data_path):\n",
    "        # Cast to float because othewise we run into a type\n",
    "        # mismatch error in PyTorch\n",
    "        season_df = pd.read_csv(\n",
    "            fp, index_col=[0, 1], header=[0, 1, 2], dtype='float32')\n",
    "        \n",
    "        df = df.append(season_df)\n",
    "    \n",
    "    features = df[['this', 'other']]\n",
    "    scores = df['TEAM_PTS']\n",
    "    msg = 'Uh oh, you might be losing features!'\n",
    "    assert len(features.columns) + len(scores.columns) == len(df.columns), msg\n",
    "    \n",
    "    features = torch.from_numpy(features.values)\n",
    "    scores = torch.from_numpy(scores.values)\n",
    "    \n",
    "    return features, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_two_layers(n: int) -> List[Union[nn.Linear, nn.ReLU]]:\n",
    "    \"\"\"Given an input of size n, construct a series\n",
    "    of neural network layers that decrease logarithmically.\n",
    "    \"\"\"\n",
    "    shift_bit_length = lambda x: 1 << (x - 1).bit_length() - 1\n",
    "    \n",
    "    layers = []\n",
    "    while n > 4:\n",
    "        power_of_two = shift_bit_length(n)\n",
    "        layers.append( nn.Linear(n, power_of_two) )\n",
    "        layers.append( nn.ReLU() )\n",
    "        n = power_of_two\n",
    "    # Now n == 4 and we add a final regression layer\n",
    "    layers.append( nn.Linear(n, 1) )\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Driver Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Roughly follows https://pytorch.org/tutorials/beginner/nn_tutorial.html#\n",
    "\n",
    "# Model hyperparameters\n",
    "num_epochs = 200\n",
    "batch_size = 100\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# Load data as torch.tensors\n",
    "x_train, y_train = get_data('train')\n",
    "x_validate, y_validate = get_data('dev')\n",
    "\n",
    "# Define our model layers by decreasing powers of two\n",
    "model = nn.Sequential(*log_two_layers(x_train.shape[1]))\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "validate_ds = TensorDataset(x_validate, y_validate)\n",
    "validate_dl = DataLoader(validate_ds, batch_size=batch_size * 2)\n",
    "\n",
    "# L1 loss more robust to outliers\n",
    "# loss_func = F.l1_loss\n",
    "loss_func = F.mse_loss\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for xb, yb in train_dl:\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        validate_loss = sum(loss_func(model(xb), yb) for xb, yb in validate_dl)\n",
    "\n",
    "    # Print epoch number and average validation loss\n",
    "    print(epoch, validate_loss / len(validate_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = get_data('test')\n",
    "\n",
    "pred = model(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[101.3214],\n",
       "        [101.3214],\n",
       "        [101.3214],\n",
       "        ...,\n",
       "        [101.3214],\n",
       "        [101.3214],\n",
       "        [101.3214]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
