{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from typing import Tuple, List, Union\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_data(_type: str) -> Tuple[pd.Index, torch.tensor, torch.tensor]:\n",
    "    \"\"\"Retrieve features and outcomes from the proper directory so we can\n",
    "    feed them into a PyTorch model.\n",
    "    \n",
    "    Parameters:\n",
    "        _type: Choose from 'train', 'dev', or 'test'\n",
    "        \n",
    "    Returns:\n",
    "        A 3-tuple consisting of\n",
    "            1) A pd.Index so we can associate the outcomes predicted\n",
    "            by our model to a particular gameid/teamid\n",
    "            \n",
    "            2) A 2D torch.tensor of player/team features normalized by column\n",
    "            \n",
    "            3) A 1D torch.tensor that represents the points scored by a team\n",
    "            in a particular game.\n",
    "    \"\"\"\n",
    "    if _type not in {'train', 'dev', 'test'}:\n",
    "        msg = f\"{_type} not supported. Try 'train', 'dev', or 'test'.\"\n",
    "        raise RuntimeError(msg)\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    data_path = os.path.join('data', _type, '*-data.csv')\n",
    "    for fp in glob.glob(data_path):\n",
    "        # Cast to float because othewise we run into a type\n",
    "        # mismatch error in PyTorch\n",
    "        season_df = pd.read_csv(\n",
    "            fp, index_col=[0, 1], header=[0, 1, 2], dtype='float32')\n",
    "        \n",
    "        df = df.append(season_df)\n",
    "    \n",
    "    features = df[['this', 'other']]\n",
    "    # Normalize features\n",
    "    features = (features - features.mean()) / features.std()\n",
    "    scores = df['TEAM_PTS']\n",
    "    \n",
    "    n_features = len(features.columns)\n",
    "    n_output = len(scores.columns)\n",
    "    msg = 'Uh oh, you might be losing features!'\n",
    "    assert n_features + n_output == len(df.columns), msg\n",
    "    \n",
    "    features = torch.from_numpy(features.values)\n",
    "    scores = torch.from_numpy(scores.values)\n",
    "    \n",
    "    return df.index, features, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_odds_data(_type: str) -> pd.DataFrame:\n",
    "    \"\"\"Load the odds DataFrame for a certain domain.\n",
    "    \n",
    "    Parameters:\n",
    "        _type: Choose from 'train', 'dev', or 'test'\n",
    "        \n",
    "    Returns:\n",
    "        A pd.DataFrame indexed by (GAME_ID, TEAM_ID)\n",
    "    \"\"\"\n",
    "    if _type not in {'train', 'dev', 'test'}:\n",
    "        msg = f\"{_type} not supported. Try 'train', 'dev', or 'test'.\"\n",
    "        raise RuntimeError(msg)\n",
    "        \n",
    "    df = pd.DataFrame()\n",
    "    data_path = os.path.join('data', _type, '*-odds.csv')\n",
    "    for fp in glob.glob(data_path):\n",
    "        season_df = pd.read_csv(fp, index_col=[0, 1])\n",
    "        df = df.append(season_df)\n",
    "        \n",
    "    df = df.reset_index()\n",
    "    df = df.set_index(['GAME_ID', 'TEAM_ID'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_two_layers(n: int) -> List[Union[nn.Linear, nn.ReLU]]:\n",
    "    \"\"\"Given an input with n features, construct a series\n",
    "    of neural network layers that decrease logarithmically.\n",
    "    \"\"\"\n",
    "    shift_bit_length = lambda x: 1 << (x - 1).bit_length() - 1\n",
    "    \n",
    "    layers = []\n",
    "    while n > 4:\n",
    "        power_of_two = shift_bit_length(n)\n",
    "        # I belive nn.Linear uses Xavier initialization\n",
    "        layers.append( nn.Linear(n, power_of_two) )\n",
    "        layers.append( nn.ReLU() )\n",
    "        n = power_of_two\n",
    "    # Now n == 4 and we add a final regression layer\n",
    "    layers.append( nn.Linear(n, 1) )\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Model Logic/Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Roughly follows https://pytorch.org/tutorials/beginner/nn_tutorial.html#\n",
    "\n",
    "# Model hyperparameters\n",
    "num_epochs = 400\n",
    "batch_size = 100\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# Load data as torch.tensors\n",
    "_, x_train, y_train = load_model_data('train')\n",
    "_, x_validate, y_validate = load_model_data('dev')\n",
    "\n",
    "# Define our model layers by decreasing powers of two\n",
    "model = nn.Sequential( *log_two_layers(x_train.shape[1]) )\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "validate_ds = TensorDataset(x_validate, y_validate)\n",
    "validate_dl = DataLoader(validate_ds, batch_size=batch_size * 2)\n",
    "\n",
    "# L1 loss is more robust to outliers\n",
    "loss_func = F.l1_loss\n",
    "# loss_func = F.mse_loss\n",
    "\n",
    "avg_validation_losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for xb, yb in train_dl:\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        epoch_loss = sum(loss_func(model(xb), yb) for xb, yb in validate_dl)\n",
    "        avg_validation_losses.append( epoch_loss / len(validate_dl) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('L1 Validation Loss vs. Epoch')\n",
    "plt.plot(avg_validation_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_t, x_test, y_test = load_model_data('test')\n",
    "\n",
    "y_predicted = model(x_test)\n",
    "y_hat = pd.Series(y_predicted.detach().squeeze(), index=i_t)\n",
    "\n",
    "odds = load_odds_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
